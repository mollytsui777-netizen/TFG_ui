## 背景
- 原始 TalkingGaussian 推理（`synthesize_fuse.py`）按训练帧数渲染，不会自动随长音频扩展帧数。
- 训练数据典型约 4 秒（~100 帧）。当输入长音频（例如 4 分钟）时，生成视频只会有训练帧长度的画面，后续时长画面静止或僵硬。

## 现象
- 日志显示音频特征时长 242s，但生成无声视频只有 ~4s。
- 后续裁剪、合成音轨无法让画面变长，表现为“僵尸头”：后半段头部不动、眨眼停滞，只剩嘴型/音频。

## 根因
- `render_sets` 仅遍历训练时的 camera/frames（`transforms_train.json`），帧数固定；音频更长不会自动补帧。

## 解决方案（已实现）
- 文件：`TalkingGaussian/scene/dataset_readers.py`
- 核心：长音频时对 frames 做“镜像循环”扩展
  - 构造循环序列：`0,1,...,N-1,N-2,...,1`，长度 `2N-2`，按音频帧数取模追加。
  - 扩展帧复用源帧的 `img_id`，确保 ori_imgs/gt_imgs/parsing/teeth_mask 等文件存在且可读。
  - AU / 眨眼直接随循环的 `img_id` 取值，表情和眨眼也随循环重复，避免“平均表情”僵硬。
  - landmarks / 几何随循环重新计算，`img_id` 在 talking_dict 中用渲染顺序的 idx 保持连续。
  - 兜底：若某文件缺失，退回使用最后一帧标注。

## 预期效果
- 长音频可生成全程有画面的视频，头部动作镜像往复，不再定格，眨眼也随 AU 循环。
- 与原始短音频/短视频行为兼容（当音频长度 <= 训练帧数时不触发扩展）。

## 相关文件
- `TalkingGaussian/scene/dataset_readers.py`：镜像扩帧与表情/眨眼循环的实现。
- 其他文件未改动推理时长行为。

## 仍需注意
- 镜像循环在首尾仍可能有轻微拼接感，如需更平滑可再做淡入淡出或插值（当前未实现）。
- 若训练数据帧数极少，循环仍可能显得单调，建议适当增加训练视频时长或多样性。 

